{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#   tf.keras.layers.Dense(128, activation='tanh'),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(10)\n",
    "# ])\n",
    "\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=loss_fn,\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for NN\n",
    "y_train = onehot(y_train).T\n",
    "y_test = onehot(y_test).T\n",
    "x_train = x_train.reshape(len(x_train), 784)\n",
    "x_test = x_test.reshape(len(x_test), 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.15525954712348036\n",
      "Epoch 1, Loss: 0.05\n",
      "Epoch 2, Loss: 0.09024833333333333\n",
      "Epoch 3, Loss: 0.13039166666666666\n",
      "Epoch 4, Loss: 0.288395\n",
      "Epoch 5, Loss: 0.090965\n",
      "Epoch 6, Loss: 0.05\n",
      "Epoch 7, Loss: 0.05\n",
      "Epoch 8, Loss: 0.05\n",
      "Epoch 9, Loss: 0.05\n",
      "Epoch 10, Loss: 0.05\n",
      "Epoch 11, Loss: 0.24896166666666666\n",
      "Epoch 12, Loss: 0.21007333333333333\n",
      "Epoch 13, Loss: 0.05\n",
      "Epoch 14, Loss: 0.090965\n",
      "Epoch 15, Loss: 0.05\n",
      "Epoch 16, Loss: 0.05\n",
      "Epoch 17, Loss: 0.05\n",
      "Epoch 18, Loss: 0.08876333333333333\n",
      "Epoch 19, Loss: 0.21019833333333332\n",
      "Train accuracy:  0.902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test_nn import *\n",
    "\n",
    "nn = NeuralNetwork([784, 256, 256, 10], [Sigmoid(), Sigmoid(), Sigmoid()], MeanSquaredError())\n",
    "\n",
    "nn.train(x_train, y_train, epochs=20, learning_rate=0.0001)\n",
    "\n",
    "yhat = np.array([nn.predict_multi(x) for x in x_test])\n",
    "print(\"Train accuracy: \", accuracy_binary(yhat, y_test))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[10])\n",
    "print(yhat[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.11290380168063086\n",
      "Epoch 1, Loss: 0.10801744660745811\n",
      "Epoch 2, Loss: 0.10711705322321634\n",
      "Epoch 3, Loss: 0.10659910684530778\n",
      "Epoch 4, Loss: 0.10617214774198512\n",
      "Epoch 5, Loss: 0.1057704188652978\n",
      "Epoch 6, Loss: 0.10537430848832847\n",
      "Epoch 7, Loss: 0.10498484829401966\n",
      "Epoch 8, Loss: 0.10459817671168677\n",
      "Epoch 9, Loss: 0.10421587347023394\n",
      "Epoch 10, Loss: 0.10383674318882592\n",
      "Epoch 11, Loss: 0.10346131332717044\n",
      "Epoch 12, Loss: 0.1030891718653489\n",
      "Epoch 13, Loss: 0.10272043427359108\n",
      "Epoch 14, Loss: 0.1023549339906844\n",
      "Epoch 15, Loss: 0.10199265923279273\n",
      "Epoch 16, Loss: 0.10163351891233552\n",
      "Epoch 17, Loss: 0.10127746665341286\n",
      "Epoch 18, Loss: 0.10092443541876822\n",
      "Epoch 19, Loss: 0.1005743716352357\n",
      "Epoch 20, Loss: 0.1002272173685055\n",
      "Epoch 21, Loss: 0.09988291948604494\n",
      "Epoch 22, Loss: 0.09954142486607427\n",
      "Epoch 23, Loss: 0.09920268279393883\n",
      "Epoch 24, Loss: 0.09886664367188663\n",
      "Epoch 25, Loss: 0.09853325961527341\n",
      "Epoch 26, Loss: 0.09820248408828465\n",
      "Epoch 27, Loss: 0.09787427202904246\n",
      "Epoch 28, Loss: 0.09754857972778504\n",
      "Epoch 29, Loss: 0.09722536483102018\n",
      "Epoch 30, Loss: 0.09690458628325622\n",
      "Epoch 31, Loss: 0.09658620430122968\n",
      "Epoch 32, Loss: 0.0962701803328934\n",
      "Epoch 33, Loss: 0.09595647702508997\n",
      "Epoch 34, Loss: 0.09564505818791984\n",
      "Epoch 35, Loss: 0.09533588876177389\n",
      "Epoch 36, Loss: 0.09502893478403934\n",
      "Epoch 37, Loss: 0.09472416335694885\n",
      "Epoch 38, Loss: 0.09442154261582762\n",
      "Epoch 39, Loss: 0.09412104169809143\n",
      "Epoch 40, Loss: 0.09382263071280587\n",
      "Epoch 41, Loss: 0.09352628071088549\n",
      "Epoch 42, Loss: 0.09323196365587964\n",
      "Epoch 43, Loss: 0.09293965239535697\n",
      "Epoch 44, Loss: 0.09264932063286978\n",
      "Epoch 45, Loss: 0.09236094290049436\n",
      "Epoch 46, Loss: 0.09207449453193678\n",
      "Epoch 47, Loss: 0.09178995163619712\n",
      "Epoch 48, Loss: 0.09150729107178489\n",
      "Epoch 49, Loss: 0.09122649042147761\n",
      "Epoch 50, Loss: 0.09094752796761622\n",
      "Epoch 51, Loss: 0.09067038266793064\n",
      "Epoch 52, Loss: 0.09039503413188876\n",
      "Epoch 53, Loss: 0.09012146259756355\n",
      "Epoch 54, Loss: 0.08984964890901148\n",
      "Epoch 55, Loss: 0.08957957449415783\n",
      "Epoch 56, Loss: 0.08931122134318255\n",
      "Epoch 57, Loss: 0.08904457198740234\n",
      "Epoch 58, Loss: 0.08877960947864366\n",
      "Epoch 59, Loss: 0.08851631736910202\n",
      "Epoch 60, Loss: 0.08825467969168309\n",
      "Epoch 61, Loss: 0.08799468094082101\n",
      "Epoch 62, Loss: 0.08773630605377013\n",
      "Epoch 63, Loss: 0.0874795403923652\n",
      "Epoch 64, Loss: 0.0872243697252469\n",
      "Epoch 65, Loss: 0.08697078021054805\n",
      "Epoch 66, Loss: 0.08671875837903677\n",
      "Epoch 67, Loss: 0.08646829111771293\n",
      "Epoch 68, Loss: 0.08621936565385378\n",
      "Epoch 69, Loss: 0.0859719695395051\n",
      "Epoch 70, Loss: 0.08572609063641408\n",
      "Epoch 71, Loss: 0.08548171710139996\n",
      "Epoch 72, Loss: 0.08523883737215865\n",
      "Epoch 73, Loss: 0.08499744015349753\n",
      "Epoch 74, Loss: 0.08475751440399641\n",
      "Epoch 75, Loss: 0.08451904932309046\n",
      "Epoch 76, Loss: 0.0842820343385714\n",
      "Epoch 77, Loss: 0.0840464590945025\n",
      "Epoch 78, Loss: 0.08381231343954298\n",
      "Epoch 79, Loss: 0.0835795874156781\n",
      "Epoch 80, Loss: 0.08334827124734939\n",
      "Epoch 81, Loss: 0.08311835533098154\n",
      "Epoch 82, Loss: 0.08288983022490047\n",
      "Epoch 83, Loss: 0.08266268663963781\n",
      "Epoch 84, Loss: 0.08243691542861714\n",
      "Epoch 85, Loss: 0.08221250757921654\n",
      "Epoch 86, Loss: 0.08198945420420208\n",
      "Epoch 87, Loss: 0.08176774653352727\n",
      "Epoch 88, Loss: 0.0815473759064924\n",
      "Epoch 89, Loss: 0.0813283337642583\n",
      "Epoch 90, Loss: 0.0811106116427086\n",
      "Epoch 91, Loss: 0.0808942011656545\n",
      "Epoch 92, Loss: 0.08067909403837596\n",
      "Epoch 93, Loss: 0.08046528204149268\n",
      "Epoch 94, Loss: 0.08025275702515897\n",
      "Epoch 95, Loss: 0.08004151090357542\n",
      "Epoch 96, Loss: 0.0798315356498111\n",
      "Epoch 97, Loss: 0.07962282329092922\n",
      "Epoch 98, Loss: 0.07941536590340927\n",
      "Epoch 99, Loss: 0.0792091556088589\n",
      "Epoch 100, Loss: 0.07900418457000796\n",
      "Epoch 101, Loss: 0.07880044498697812\n",
      "Epoch 102, Loss: 0.07859792909381959\n",
      "Epoch 103, Loss: 0.07839662915530916\n",
      "Epoch 104, Loss: 0.07819653746400036\n",
      "Epoch 105, Loss: 0.07799764633751939\n",
      "Epoch 106, Loss: 0.07779994811609899\n",
      "Epoch 107, Loss: 0.07760343516034186\n",
      "Epoch 108, Loss: 0.07740809984920732\n",
      "Epoch 109, Loss: 0.07721393457821198\n",
      "Epoch 110, Loss: 0.07702093175783799\n",
      "Epoch 111, Loss: 0.07682908381214033\n",
      "Epoch 112, Loss: 0.07663838317754583\n",
      "Epoch 113, Loss: 0.07644882230183596\n",
      "Epoch 114, Loss: 0.07626039364330597\n",
      "Epoch 115, Loss: 0.07607308967009256\n",
      "Epoch 116, Loss: 0.07588690285966244\n",
      "Epoch 117, Loss: 0.07570182569845453\n",
      "Epoch 118, Loss: 0.07551785068166776\n",
      "Epoch 119, Loss: 0.07533497031318781\n",
      "Epoch 120, Loss: 0.07515317710564477\n",
      "Epoch 121, Loss: 0.07497246358059478\n",
      "Epoch 122, Loss: 0.07479282226881864\n",
      "Epoch 123, Loss: 0.07461424571073\n",
      "Epoch 124, Loss: 0.0744367264568865\n",
      "Epoch 125, Loss: 0.07426025706859697\n",
      "Epoch 126, Loss: 0.07408483011861795\n",
      "Epoch 127, Loss: 0.07391043819193294\n",
      "Epoch 128, Loss: 0.07373707388660819\n",
      "Epoch 129, Loss: 0.07356472981471861\n",
      "Epoch 130, Loss: 0.07339339860333761\n",
      "Epoch 131, Loss: 0.07322307289558516\n",
      "Epoch 132, Loss: 0.07305374535172807\n",
      "Epoch 133, Loss: 0.07288540865032689\n",
      "Epoch 134, Loss: 0.07271805548942413\n",
      "Epoch 135, Loss: 0.07255167858776823\n",
      "Epoch 136, Loss: 0.07238627068606851\n",
      "Epoch 137, Loss: 0.0722218245482757\n",
      "Epoch 138, Loss: 0.07205833296288397\n",
      "Epoch 139, Loss: 0.07189578874424894\n",
      "Epoch 140, Loss: 0.07173418473391835\n",
      "Epoch 141, Loss: 0.07157351380197015\n",
      "Epoch 142, Loss: 0.07141376884835476\n",
      "Epoch 143, Loss: 0.07125494280423712\n",
      "Epoch 144, Loss: 0.07109702863333517\n",
      "Epoch 145, Loss: 0.07094001933325116\n",
      "Epoch 146, Loss: 0.07078390793679222\n",
      "Epoch 147, Loss: 0.07062868751327785\n",
      "Epoch 148, Loss: 0.07047435116983004\n",
      "Epoch 149, Loss: 0.07032089205264479\n",
      "Epoch 150, Loss: 0.07016830334824098\n",
      "Epoch 151, Loss: 0.07001657828468529\n",
      "Epoch 152, Loss: 0.06986571013278997\n",
      "Epoch 153, Loss: 0.06971569220728226\n",
      "Epoch 154, Loss: 0.06956651786794232\n",
      "Epoch 155, Loss: 0.06941818052070929\n",
      "Epoch 156, Loss: 0.06927067361875255\n",
      "Epoch 157, Loss: 0.0691239906635075\n",
      "Epoch 158, Loss: 0.06897812520567405\n",
      "Epoch 159, Loss: 0.068833070846177\n",
      "Epoch 160, Loss: 0.0686888212370867\n",
      "Epoch 161, Loss: 0.06854537008249971\n",
      "Epoch 162, Loss: 0.06840271113937794\n",
      "Epoch 163, Loss: 0.06826083821834619\n",
      "Epoch 164, Loss: 0.06811974518444706\n",
      "Epoch 165, Loss: 0.06797942595785306\n",
      "Epoch 166, Loss: 0.06783987451453534\n",
      "Epoch 167, Loss: 0.06770108488688897\n",
      "Epoch 168, Loss: 0.06756305116431462\n",
      "Epoch 169, Loss: 0.06742576749375628\n",
      "Epoch 170, Loss: 0.06728922808019562\n",
      "Epoch 171, Loss: 0.06715342718710249\n",
      "Epoch 172, Loss: 0.06701835913684225\n",
      "Epoch 173, Loss: 0.06688401831103992\n",
      "Epoch 174, Loss: 0.0667503991509017\n",
      "Epoch 175, Loss: 0.06661749615749407\n",
      "Epoch 176, Loss: 0.0664853038919812\n",
      "Epoch 177, Loss: 0.06635381697582109\n",
      "Epoch 178, Loss: 0.0662230300909208\n",
      "Epoch 179, Loss: 0.06609293797975226\n",
      "Epoch 180, Loss: 0.06596353544542792\n",
      "Epoch 181, Loss: 0.0658348173517388\n",
      "Epoch 182, Loss: 0.06570677862315397\n",
      "Epoch 183, Loss: 0.06557941424478356\n",
      "Epoch 184, Loss: 0.06545271926230557\n",
      "Epoch 185, Loss: 0.06532668878185745\n",
      "Epoch 186, Loss: 0.06520131796989329\n",
      "Epoch 187, Loss: 0.06507660205300804\n",
      "Epoch 188, Loss: 0.06495253631772889\n",
      "Epoch 189, Loss: 0.06482911611027553\n",
      "Epoch 190, Loss: 0.06470633683628994\n",
      "Epoch 191, Loss: 0.06458419396053676\n",
      "Epoch 192, Loss: 0.06446268300657515\n",
      "Epoch 193, Loss: 0.06434179955640347\n",
      "Epoch 194, Loss: 0.06422153925007741\n",
      "Epoch 195, Loss: 0.06410189778530302\n",
      "Epoch 196, Loss: 0.06398287091700511\n",
      "Epoch 197, Loss: 0.06386445445687272\n",
      "Epoch 198, Loss: 0.06374664427288212\n",
      "Epoch 199, Loss: 0.06362943628879873\n",
      "Epoch 200, Loss: 0.0635128264836586\n",
      "Epoch 201, Loss: 0.06339681089123099\n",
      "Epoch 202, Loss: 0.06328138559946243\n",
      "Epoch 203, Loss: 0.06316654674990375\n",
      "Epoch 204, Loss: 0.06305229053712075\n",
      "Epoch 205, Loss: 0.06293861320808962\n",
      "Epoch 206, Loss: 0.06282551106157801\n",
      "Epoch 207, Loss: 0.0627129804475125\n",
      "Epoch 208, Loss: 0.06260101776633388\n",
      "Epoch 209, Loss: 0.06248961946834062\n",
      "Epoch 210, Loss: 0.06237878205302146\n",
      "Epoch 211, Loss: 0.06226850206837845\n",
      "Epoch 212, Loss: 0.06215877611024079\n",
      "Epoch 213, Loss: 0.06204960082157048\n",
      "Epoch 214, Loss: 0.061940972891760475\n",
      "Epoch 215, Loss: 0.06183288905592647\n",
      "Epoch 216, Loss: 0.061725346094192585\n",
      "Epoch 217, Loss: 0.06161834083097215\n",
      "Epoch 218, Loss: 0.06151187013424395\n",
      "Epoch 219, Loss: 0.061405930914824845\n",
      "Epoch 220, Loss: 0.061300520125639524\n",
      "Epoch 221, Loss: 0.06119563476098771\n",
      "Epoch 222, Loss: 0.06109127185580985\n",
      "Epoch 223, Loss: 0.060987428484951665\n",
      "Epoch 224, Loss: 0.06088410176242819\n",
      "Epoch 225, Loss: 0.060781288840688064\n",
      "Epoch 226, Loss: 0.060678986909878295\n",
      "Epoch 227, Loss: 0.06057719319711041\n",
      "Epoch 228, Loss: 0.06047590496572821\n",
      "Epoch 229, Loss: 0.06037511951457777\n",
      "Epoch 230, Loss: 0.06027483417728021\n",
      "Epoch 231, Loss: 0.0601750463215075\n",
      "Epoch 232, Loss: 0.06007575334826195\n",
      "Epoch 233, Loss: 0.05997695269115976\n",
      "Epoch 234, Loss: 0.059878641815718746\n",
      "Epoch 235, Loss: 0.0597808182186513\n",
      "Epoch 236, Loss: 0.05968347942716201\n",
      "Epoch 237, Loss: 0.05958662299825122\n",
      "Epoch 238, Loss: 0.059490246518024155\n",
      "Epoch 239, Loss: 0.05939434760100646\n",
      "Epoch 240, Loss: 0.059298923889465845\n",
      "Epoch 241, Loss: 0.05920397305274089\n",
      "Epoch 242, Loss: 0.059109492786576456\n",
      "Epoch 243, Loss: 0.05901548081246668\n",
      "Epoch 244, Loss: 0.058921934877005276\n",
      "Epoch 245, Loss: 0.058828852751243534\n",
      "Epoch 246, Loss: 0.05873623223005631\n",
      "Epoch 247, Loss: 0.05864407113151613\n",
      "Epoch 248, Loss: 0.05855236729627556\n",
      "Epoch 249, Loss: 0.05846111858695799\n",
      "Epoch 250, Loss: 0.05837032288755702\n",
      "Epoch 251, Loss: 0.05827997810284472\n",
      "Epoch 252, Loss: 0.05819008215778861\n",
      "Epoch 253, Loss: 0.058100632996977784\n",
      "Epoch 254, Loss: 0.05801162858405787\n",
      "Epoch 255, Loss: 0.057923066901175595\n",
      "Epoch 256, Loss: 0.05783494594843223\n",
      "Epoch 257, Loss: 0.05774726374334658\n",
      "Epoch 258, Loss: 0.057660018320327494\n",
      "Epoch 259, Loss: 0.05757320773015556\n",
      "Epoch 260, Loss: 0.05748683003947458\n",
      "Epoch 261, Loss: 0.05740088333029255\n",
      "Epoch 262, Loss: 0.05731536569949198\n",
      "Epoch 263, Loss: 0.05723027525835037\n",
      "Epoch 264, Loss: 0.057145610132069626\n",
      "Epoch 265, Loss: 0.05706136845931566\n",
      "Epoch 266, Loss: 0.05697754839176731\n",
      "Epoch 267, Loss: 0.05689414809367496\n",
      "Epoch 268, Loss: 0.05681116574142881\n",
      "Epoch 269, Loss: 0.056728599523136636\n",
      "Epoch 270, Loss: 0.05664644763821117\n",
      "Epoch 271, Loss: 0.056564708296966915\n",
      "Epoch 272, Loss: 0.05648337972022662\n",
      "Epoch 273, Loss: 0.05640246013893685\n",
      "Epoch 274, Loss: 0.056321947793793355\n",
      "Epoch 275, Loss: 0.05624184093487552\n",
      "Epoch 276, Loss: 0.056162137821289926\n",
      "Epoch 277, Loss: 0.056082836720823655\n",
      "Epoch 278, Loss: 0.05600393590960612\n",
      "Epoch 279, Loss: 0.055925433671780274\n",
      "Epoch 280, Loss: 0.055847328299182895\n",
      "Epoch 281, Loss: 0.055769618091033535\n",
      "Epoch 282, Loss: 0.0556923013536324\n",
      "Epoch 283, Loss: 0.05561537640006713\n",
      "Epoch 284, Loss: 0.055538841549927886\n",
      "Epoch 285, Loss: 0.05546269512903135\n",
      "Epoch 286, Loss: 0.055386935469152854\n",
      "Epoch 287, Loss: 0.05531156090776732\n",
      "Epoch 288, Loss: 0.055236569787797986\n",
      "Epoch 289, Loss: 0.05516196045737353\n",
      "Epoch 290, Loss: 0.055087731269593376\n",
      "Epoch 291, Loss: 0.05501388058230066\n",
      "Epoch 292, Loss: 0.0549404067578634\n",
      "Epoch 293, Loss: 0.054867308162963015\n",
      "Epoch 294, Loss: 0.05479458316839073\n",
      "Epoch 295, Loss: 0.054722230148851615\n",
      "Epoch 296, Loss: 0.054650247482775555\n",
      "Epoch 297, Loss: 0.054578633552136054\n",
      "Epoch 298, Loss: 0.05450738674227582\n",
      "Epoch 299, Loss: 0.05443650544173969\n",
      "Epoch 300, Loss: 0.0543659880421142\n",
      "Epoch 301, Loss: 0.054295832937874294\n",
      "Epoch 302, Loss: 0.054226038526236454\n",
      "Epoch 303, Loss: 0.05415660320701865\n",
      "Epoch 304, Loss: 0.054087525382506586\n",
      "Epoch 305, Loss: 0.05401880345732635\n",
      "Epoch 306, Loss: 0.0539504358383234\n",
      "Epoch 307, Loss: 0.053882420934447395\n",
      "Epoch 308, Loss: 0.05381475715664331\n",
      "Epoch 309, Loss: 0.05374744291774821\n",
      "Epoch 310, Loss: 0.053680476632393836\n",
      "Epoch 311, Loss: 0.05361385671691491\n",
      "Epoch 312, Loss: 0.053547581589262705\n",
      "Epoch 313, Loss: 0.05348164966892433\n",
      "Epoch 314, Loss: 0.05341605937684701\n",
      "Epoch 315, Loss: 0.05335080913536755\n",
      "Epoch 316, Loss: 0.05328589736814712\n",
      "Epoch 317, Loss: 0.05322132250011052\n",
      "Epoch 318, Loss: 0.053157082957390495\n",
      "Epoch 319, Loss: 0.05309317716727686\n",
      "Epoch 320, Loss: 0.053029603558169824\n",
      "Epoch 321, Loss: 0.052966360559538045\n",
      "Epoch 322, Loss: 0.05290344660188095\n",
      "Epoch 323, Loss: 0.052840860116695275\n",
      "Epoch 324, Loss: 0.052778599536445724\n",
      "Epoch 325, Loss: 0.052716663294539584\n",
      "Epoch 326, Loss: 0.05265504982530526\n",
      "Epoch 327, Loss: 0.052593757563974684\n",
      "Epoch 328, Loss: 0.05253278494666919\n",
      "Epoch 329, Loss: 0.05247213041038921\n",
      "Epoch 330, Loss: 0.052411792393007146\n",
      "Epoch 331, Loss: 0.05235176933326382\n",
      "Epoch 332, Loss: 0.05229205967076811\n",
      "Epoch 333, Loss: 0.052232661845999666\n",
      "Epoch 334, Loss: 0.0521735743003148\n",
      "Epoch 335, Loss: 0.052114795475955156\n",
      "Epoch 336, Loss: 0.05205632381605935\n",
      "Epoch 337, Loss: 0.051998157764677345\n",
      "Epoch 338, Loss: 0.051940295766787416\n",
      "Epoch 339, Loss: 0.05188273626831578\n",
      "Epoch 340, Loss: 0.051825477716158495\n",
      "Epoch 341, Loss: 0.05176851855820591\n",
      "Epoch 342, Loss: 0.051711857243369456\n",
      "Epoch 343, Loss: 0.051655492221610255\n",
      "Epoch 344, Loss: 0.05159942194397025\n",
      "Epoch 345, Loss: 0.051543644862605174\n",
      "Epoch 346, Loss: 0.05148815943081934\n",
      "Epoch 347, Loss: 0.05143296410310253\n",
      "Epoch 348, Loss: 0.05137805733516828\n",
      "Epoch 349, Loss: 0.05132343758399426\n",
      "Epoch 350, Loss: 0.05126910330786392\n",
      "Epoch 351, Loss: 0.0512150529664099\n",
      "Epoch 352, Loss: 0.05116128502065854\n",
      "Epoch 353, Loss: 0.051107797933076245\n",
      "Epoch 354, Loss: 0.05105459016761671\n",
      "Epoch 355, Loss: 0.05100166018976956\n",
      "Epoch 356, Loss: 0.05094900646661015\n",
      "Epoch 357, Loss: 0.05089662746685031\n",
      "Epoch 358, Loss: 0.05084452166089026\n",
      "Epoch 359, Loss: 0.050792687520871405\n",
      "Epoch 360, Loss: 0.050741123520729875\n",
      "Epoch 361, Loss: 0.05068982813625117\n",
      "Epoch 362, Loss: 0.05063879984512518\n",
      "Epoch 363, Loss: 0.0505880371270023\n",
      "Epoch 364, Loss: 0.05053753846354969\n",
      "Epoch 365, Loss: 0.05048730233850864\n",
      "Epoch 366, Loss: 0.050437327237751996\n",
      "Epoch 367, Loss: 0.05038761164934228\n",
      "Epoch 368, Loss: 0.05033815406359022\n",
      "Epoch 369, Loss: 0.05028895297311336\n",
      "Epoch 370, Loss: 0.05024000687289534\n",
      "Epoch 371, Loss: 0.05019131426034515\n",
      "Epoch 372, Loss: 0.05014287363535674\n",
      "Epoch 373, Loss: 0.05009468350036856\n",
      "Epoch 374, Loss: 0.05004674236042348\n",
      "Epoch 375, Loss: 0.049999048723228634\n",
      "Epoch 376, Loss: 0.049951601099215086\n",
      "Epoch 377, Loss: 0.04990439800159787\n",
      "Epoch 378, Loss: 0.049857437946435566\n",
      "Epoch 379, Loss: 0.049810719452690035\n",
      "Epoch 380, Loss: 0.04976424104228583\n",
      "Epoch 381, Loss: 0.0497180012401695\n",
      "Epoch 382, Loss: 0.049671998574368624\n",
      "Epoch 383, Loss: 0.04962623157605064\n",
      "Epoch 384, Loss: 0.04958069877958135\n",
      "Epoch 385, Loss: 0.049535398722583\n",
      "Epoch 386, Loss: 0.04949032994599218\n",
      "Epoch 387, Loss: 0.04944549099411722\n",
      "Epoch 388, Loss: 0.04940088041469515\n",
      "Epoch 389, Loss: 0.04935649675894821\n",
      "Epoch 390, Loss: 0.049312338581640004\n",
      "Epoch 391, Loss: 0.04926840444113093\n",
      "Epoch 392, Loss: 0.049224692899433375\n",
      "Epoch 393, Loss: 0.04918120252226601\n",
      "Epoch 394, Loss: 0.04913793187910779\n",
      "Epoch 395, Loss: 0.04909487954325122\n",
      "Epoch 396, Loss: 0.049052044091855006\n",
      "Epoch 397, Loss: 0.049009424105996145\n",
      "Epoch 398, Loss: 0.04896701817072121\n",
      "Epoch 399, Loss: 0.04892482487509703\n",
      "Epoch 400, Loss: 0.04888284281226085\n",
      "Epoch 401, Loss: 0.04884107057946938\n",
      "Epoch 402, Loss: 0.048799506778147504\n",
      "Epoch 403, Loss: 0.048758150013935984\n",
      "Epoch 404, Loss: 0.048716998896738556\n",
      "Epoch 405, Loss: 0.04867605204076821\n",
      "Epoch 406, Loss: 0.04863530806459255\n",
      "Epoch 407, Loss: 0.048594765591178736\n",
      "Epoch 408, Loss: 0.048554423247937\n",
      "Epoch 409, Loss: 0.04851427966676406\n",
      "Epoch 410, Loss: 0.04847433348408515\n",
      "Epoch 411, Loss: 0.04843458334089546\n",
      "Epoch 412, Loss: 0.048395027882800694\n",
      "Epoch 413, Loss: 0.048355665760056794\n",
      "Epoch 414, Loss: 0.04831649562760874\n",
      "Epoch 415, Loss: 0.04827751614512854\n",
      "Epoch 416, Loss: 0.048238725977052366\n",
      "Epoch 417, Loss: 0.04820012379261671\n",
      "Epoch 418, Loss: 0.048161708265893916\n",
      "Epoch 419, Loss: 0.04812347807582636\n",
      "Epoch 420, Loss: 0.048085431906260356\n",
      "Epoch 421, Loss: 0.04804756844597863\n",
      "Epoch 422, Loss: 0.04800988638873221\n",
      "Epoch 423, Loss: 0.04797238443327139\n",
      "Epoch 424, Loss: 0.04793506128337561\n",
      "Epoch 425, Loss: 0.04789791564788279\n",
      "Epoch 426, Loss: 0.047860946240717385\n",
      "Epoch 427, Loss: 0.0478241517809179\n",
      "Epoch 428, Loss: 0.0477875309926632\n",
      "Epoch 429, Loss: 0.04775108260529823\n",
      "Epoch 430, Loss: 0.047714805353358536\n",
      "Epoch 431, Loss: 0.04767869797659421\n",
      "Epoch 432, Loss: 0.047642759219992725\n",
      "Epoch 433, Loss: 0.04760698783380104\n",
      "Epoch 434, Loss: 0.047571382573546685\n",
      "Epoch 435, Loss: 0.047535942200058086\n",
      "Epoch 436, Loss: 0.04750066547948406\n",
      "Epoch 437, Loss: 0.04746555118331223\n",
      "Epoch 438, Loss: 0.04743059808838692\n",
      "Epoch 439, Loss: 0.04739580497692578\n",
      "Epoch 440, Loss: 0.047361170636536026\n",
      "Epoch 441, Loss: 0.04732669386022944\n",
      "Epoch 442, Loss: 0.047292373446436754\n",
      "Epoch 443, Loss: 0.047258208199021136\n",
      "Epoch 444, Loss: 0.04722419692729093\n",
      "Epoch 445, Loss: 0.04719033844601137\n",
      "Epoch 446, Loss: 0.04715663157541581\n",
      "Epoch 447, Loss: 0.04712307514121581\n",
      "Epoch 448, Loss: 0.04708966797461073\n",
      "Epoch 449, Loss: 0.04705640891229631\n",
      "Epoch 450, Loss: 0.04702329679647255\n",
      "Epoch 451, Loss: 0.04699033047485093\n",
      "Epoch 452, Loss: 0.04695750880066061\n",
      "Epoch 453, Loss: 0.04692483063265418\n",
      "Epoch 454, Loss: 0.046892294835112446\n",
      "Epoch 455, Loss: 0.046859900277848476\n",
      "Epoch 456, Loss: 0.046827645836211164\n",
      "Epoch 457, Loss: 0.046795530391087754\n",
      "Epoch 458, Loss: 0.04676355282890582\n",
      "Epoch 459, Loss: 0.04673171204163453\n",
      "Epoch 460, Loss: 0.046700006926785276\n",
      "Epoch 461, Loss: 0.046668436387411395\n",
      "Epoch 462, Loss: 0.04663699933210755\n",
      "Epoch 463, Loss: 0.04660569467500817\n",
      "Epoch 464, Loss: 0.046574521335785345\n",
      "Epoch 465, Loss: 0.04654347823964605\n",
      "Epoch 466, Loss: 0.04651256431732879\n",
      "Epoch 467, Loss: 0.04648177850509954\n",
      "Epoch 468, Loss: 0.04645111974474708\n",
      "Epoch 469, Loss: 0.0464205869835779\n",
      "Epoch 470, Loss: 0.04639017917441004\n",
      "Epoch 471, Loss: 0.04635989527556702\n",
      "Epoch 472, Loss: 0.04632973425087048\n",
      "Epoch 473, Loss: 0.046299695069632996\n",
      "Epoch 474, Loss: 0.04626977670664952\n",
      "Epoch 475, Loss: 0.04623997814218896\n",
      "Epoch 476, Loss: 0.04621029836198493\n",
      "Epoch 477, Loss: 0.046180736357225895\n",
      "Epoch 478, Loss: 0.04615129112454497\n",
      "Epoch 479, Loss: 0.04612196166600905\n",
      "Epoch 480, Loss: 0.04609274698910774\n",
      "Epoch 481, Loss: 0.046063646106741324\n",
      "Epoch 482, Loss: 0.046034658037208624\n",
      "Epoch 483, Loss: 0.0460057818041944\n",
      "Epoch 484, Loss: 0.04597701643675591\n",
      "Epoch 485, Loss: 0.04594836096930952\n",
      "Epoch 486, Loss: 0.04591981444161647\n",
      "Epoch 487, Loss: 0.0458913758987684\n",
      "Epoch 488, Loss: 0.04586304439117255\n",
      "Epoch 489, Loss: 0.0458348189745362\n",
      "Epoch 490, Loss: 0.04580669870985107\n",
      "Epoch 491, Loss: 0.045778682663377146\n",
      "Epoch 492, Loss: 0.04575076990662618\n",
      "Epoch 493, Loss: 0.04572295951634473\n",
      "Epoch 494, Loss: 0.045695250574496915\n",
      "Epoch 495, Loss: 0.04566764216824685\n",
      "Epoch 496, Loss: 0.04564013338994057\n",
      "Epoch 497, Loss: 0.04561272333708777\n",
      "Epoch 498, Loss: 0.04558541111234319\n",
      "Epoch 499, Loss: 0.04555819582348758\n",
      "Epoch 500, Loss: 0.0455310765834085\n",
      "Epoch 501, Loss: 0.04550405251008063\n",
      "Epoch 502, Loss: 0.04547712272654597\n",
      "Epoch 503, Loss: 0.045450286360893655\n",
      "Epoch 504, Loss: 0.04542354254623949\n",
      "Epoch 505, Loss: 0.04539689042070524\n",
      "Epoch 506, Loss: 0.045370329127397635\n",
      "Epoch 507, Loss: 0.045343857814387135\n",
      "Epoch 508, Loss: 0.04531747563468649\n",
      "Epoch 509, Loss: 0.04529118174622889\n",
      "Epoch 510, Loss: 0.045264975311846166\n",
      "Epoch 511, Loss: 0.04523885549924649\n",
      "Epoch 512, Loss: 0.04521282148099209\n",
      "Epoch 513, Loss: 0.045186872434476465\n",
      "Epoch 514, Loss: 0.045161007541901825\n",
      "Epoch 515, Loss: 0.045135225990255885\n",
      "Epoch 516, Loss: 0.04510952697128878\n",
      "Epoch 517, Loss: 0.045083909681489676\n",
      "Epoch 518, Loss: 0.0450583733220633\n",
      "Epoch 519, Loss: 0.045032917098906076\n",
      "Epoch 520, Loss: 0.04500754022258243\n",
      "Epoch 521, Loss: 0.044982241908300725\n",
      "Epoch 522, Loss: 0.044957021375889104\n",
      "Epoch 523, Loss: 0.04493187784977121\n",
      "Epoch 524, Loss: 0.04490681055894171\n",
      "Epoch 525, Loss: 0.0448818187369418\n",
      "Epoch 526, Loss: 0.044856901621834554\n",
      "Epoch 527, Loss: 0.04483205845618008\n",
      "Epoch 528, Loss: 0.0448072884870107\n",
      "Epoch 529, Loss: 0.044782590965805925\n",
      "Epoch 530, Loss: 0.04475796514846736\n",
      "Epoch 531, Loss: 0.04473341029529362\n",
      "Epoch 532, Loss: 0.04470892567095495\n",
      "Epoch 533, Loss: 0.04468451054446798\n",
      "Epoch 534, Loss: 0.04466016418917033\n",
      "Epoch 535, Loss: 0.044635885882695146\n",
      "Epoch 536, Loss: 0.04461167490694546\n",
      "Epoch 537, Loss: 0.044587530548068806\n",
      "Epoch 538, Loss: 0.04456345209643139\n",
      "Epoch 539, Loss: 0.044539438846592526\n",
      "Epoch 540, Loss: 0.04451549009727895\n",
      "Epoch 541, Loss: 0.044491605151358936\n",
      "Epoch 542, Loss: 0.04446778331581663\n",
      "Epoch 543, Loss: 0.04444402390172617\n",
      "Epoch 544, Loss: 0.044420326224225946\n",
      "Epoch 545, Loss: 0.04439668960249262\n",
      "Epoch 546, Loss: 0.04437311335971538\n",
      "Epoch 547, Loss: 0.04434959682307005\n",
      "Epoch 548, Loss: 0.04432613932369322\n",
      "Epoch 549, Loss: 0.0443027401966563\n",
      "Epoch 550, Loss: 0.04427939878093982\n",
      "Epoch 551, Loss: 0.044256114419407445\n",
      "Epoch 552, Loss: 0.04423288645878017\n",
      "Epoch 553, Loss: 0.04420971424961051\n",
      "Epoch 554, Loss: 0.044186597146256744\n",
      "Epoch 555, Loss: 0.044163534506856984\n",
      "Epoch 556, Loss: 0.044140525693303685\n",
      "Epoch 557, Loss: 0.0441175700712177\n",
      "Epoch 558, Loss: 0.04409466700992264\n",
      "Epoch 559, Loss: 0.044071815882419395\n",
      "Epoch 560, Loss: 0.044049016065360325\n",
      "Epoch 561, Loss: 0.04402626693902386\n",
      "Epoch 562, Loss: 0.04400356788728892\n",
      "Epoch 563, Loss: 0.04398091829760948\n",
      "Epoch 564, Loss: 0.04395831756098919\n",
      "Epoch 565, Loss: 0.04393576507195603\n",
      "Epoch 566, Loss: 0.04391326022853703\n",
      "Epoch 567, Loss: 0.043890802432233124\n",
      "Epoch 568, Loss: 0.04386839108799385\n",
      "Epoch 569, Loss: 0.04384602560419241\n",
      "Epoch 570, Loss: 0.043823705392600644\n",
      "Epoch 571, Loss: 0.043801429868364085\n",
      "Epoch 572, Loss: 0.04377919844997713\n",
      "Epoch 573, Loss: 0.04375701055925816\n",
      "Epoch 574, Loss: 0.043734865621325024\n",
      "Epoch 575, Loss: 0.04371276306457034\n",
      "Epoch 576, Loss: 0.043690702320637015\n",
      "Epoch 577, Loss: 0.043668682824393755\n",
      "Epoch 578, Loss: 0.04364670401391079\n",
      "Epoch 579, Loss: 0.043624765330435654\n",
      "Epoch 580, Loss: 0.043602866218368876\n",
      "Epoch 581, Loss: 0.04358100612524026\n",
      "Epoch 582, Loss: 0.04355918450168456\n",
      "Epoch 583, Loss: 0.04353740080141786\n",
      "Epoch 584, Loss: 0.043515654481213806\n",
      "Epoch 585, Loss: 0.043493945000879934\n",
      "Epoch 586, Loss: 0.043472271823234106\n",
      "Epoch 587, Loss: 0.04345063441408122\n",
      "Epoch 588, Loss: 0.043429032242189664\n",
      "Epoch 589, Loss: 0.04340746477926841\n",
      "Epoch 590, Loss: 0.04338593149994368\n",
      "Epoch 591, Loss: 0.04336443188173613\n",
      "Epoch 592, Loss: 0.0433429654050379\n",
      "Epoch 593, Loss: 0.04332153155308995\n",
      "Epoch 594, Loss: 0.04330012981195939\n",
      "Epoch 595, Loss: 0.04327875967051703\n",
      "Epoch 596, Loss: 0.04325742062041494\n",
      "Epoch 597, Loss: 0.043236112156064356\n",
      "Epoch 598, Loss: 0.0432148337746133\n",
      "Epoch 599, Loss: 0.04319358497592479\n",
      "Epoch 600, Loss: 0.04317236526255493\n",
      "Epoch 601, Loss: 0.04315117413973112\n",
      "Epoch 602, Loss: 0.043130011115330415\n",
      "Epoch 603, Loss: 0.04310887569985813\n",
      "Epoch 604, Loss: 0.043087767406426454\n",
      "Epoch 605, Loss: 0.04306668575073316\n",
      "Epoch 606, Loss: 0.0430456302510406\n",
      "Epoch 607, Loss: 0.04302460042815474\n",
      "Epoch 608, Loss: 0.043003595805404284\n",
      "Epoch 609, Loss: 0.04298261590862005\n",
      "Epoch 610, Loss: 0.0429616602661144\n",
      "Epoch 611, Loss: 0.04294072840866081\n",
      "Epoch 612, Loss: 0.04291981986947365\n",
      "Epoch 613, Loss: 0.042898934184188\n",
      "Epoch 614, Loss: 0.04287807089083965\n",
      "Epoch 615, Loss: 0.04285722952984535\n",
      "Epoch 616, Loss: 0.04283640964398288\n",
      "Epoch 617, Loss: 0.04281561077837178\n",
      "Epoch 618, Loss: 0.0427948324804536\n",
      "Epoch 619, Loss: 0.04277407429997291\n",
      "Epoch 620, Loss: 0.0427533357889579\n",
      "Epoch 621, Loss: 0.04273261650170155\n",
      "Epoch 622, Loss: 0.04271191599474272\n",
      "Epoch 623, Loss: 0.042691233826847336\n",
      "Epoch 624, Loss: 0.0426705695589901\n",
      "Epoch 625, Loss: 0.042649922754335705\n",
      "Epoch 626, Loss: 0.04262929297822088\n",
      "Epoch 627, Loss: 0.042608679798136005\n",
      "Epoch 628, Loss: 0.04258808278370735\n",
      "Epoch 629, Loss: 0.04256750150667904\n",
      "Epoch 630, Loss: 0.042546935540895496\n",
      "Epoch 631, Loss: 0.04252638446228383\n",
      "Epoch 632, Loss: 0.04250584784883654\n",
      "Epoch 633, Loss: 0.042485325280594094\n",
      "Epoch 634, Loss: 0.04246481633962804\n",
      "Epoch 635, Loss: 0.04244432061002384\n",
      "Epoch 636, Loss: 0.04242383767786426\n",
      "Epoch 637, Loss: 0.042403367131212594\n",
      "Epoch 638, Loss: 0.04238290856009621\n",
      "Epoch 639, Loss: 0.04236246155649021\n",
      "Epoch 640, Loss: 0.04234202571430116\n",
      "Epoch 641, Loss: 0.04232160062935112\n",
      "Epoch 642, Loss: 0.042301185899361715\n",
      "Epoch 643, Loss: 0.042280781123938294\n",
      "Epoch 644, Loss: 0.042260385904554464\n",
      "Epoch 645, Loss: 0.042239999844536524\n",
      "Epoch 646, Loss: 0.04221962254904823\n",
      "Epoch 647, Loss: 0.04219925362507557\n",
      "Epoch 648, Loss: 0.042178892681411895\n",
      "Epoch 649, Loss: 0.04215853932864286\n",
      "Epoch 650, Loss: 0.04213819317913192\n",
      "Epoch 651, Loss: 0.04211785384700569\n",
      "Epoch 652, Loss: 0.04209752094813948\n",
      "Epoch 653, Loss: 0.04207719410014319\n",
      "Epoch 654, Loss: 0.042056872922347145\n",
      "Epoch 655, Loss: 0.04203655703578799\n",
      "Epoch 656, Loss: 0.04201624606319524\n",
      "Epoch 657, Loss: 0.041995939628977276\n",
      "Epoch 658, Loss: 0.04197563735920803\n",
      "Epoch 659, Loss: 0.04195533888161368\n",
      "Epoch 660, Loss: 0.04193504382555929\n",
      "Epoch 661, Loss: 0.04191475182203594\n",
      "Epoch 662, Loss: 0.041894462503647666\n",
      "Epoch 663, Loss: 0.041874175504598814\n",
      "Epoch 664, Loss: 0.04185389046068156\n",
      "Epoch 665, Loss: 0.041833607009263175\n",
      "Epoch 666, Loss: 0.04181332478927399\n",
      "Epoch 667, Loss: 0.04179304344119513\n",
      "Epoch 668, Loss: 0.04177276260704658\n",
      "Epoch 669, Loss: 0.04175248193037533\n",
      "Epoch 670, Loss: 0.041732201056243624\n",
      "Epoch 671, Loss: 0.04171191963121754\n",
      "Epoch 672, Loss: 0.04169163730335548\n",
      "Epoch 673, Loss: 0.04167135372219704\n",
      "Epoch 674, Loss: 0.04165106853875181\n",
      "Epoch 675, Loss: 0.04163078140548856\n",
      "Epoch 676, Loss: 0.04161049197632428\n",
      "Epoch 677, Loss: 0.04159019990661373\n",
      "Epoch 678, Loss: 0.04156990485313885\n",
      "Epoch 679, Loss: 0.04154960647409841\n",
      "Epoch 680, Loss: 0.04152930442909784\n",
      "Epoch 681, Loss: 0.04150899837913921\n",
      "Epoch 682, Loss: 0.04148868798661134\n",
      "Epoch 683, Loss: 0.04146837291528001\n",
      "Epoch 684, Loss: 0.04144805283027838\n",
      "Epoch 685, Loss: 0.04142772739809764\n",
      "Epoch 686, Loss: 0.0414073962865776\n",
      "Epoch 687, Loss: 0.0413870591648976\n",
      "Epoch 688, Loss: 0.04136671570356751\n",
      "Epoch 689, Loss: 0.04134636557441882\n",
      "Epoch 690, Loss: 0.04132600845059611\n",
      "Epoch 691, Loss: 0.04130564400654837\n",
      "Epoch 692, Loss: 0.041285271918020526\n",
      "Epoch 693, Loss: 0.04126489186204543\n",
      "Epoch 694, Loss: 0.04124450351693554\n",
      "Epoch 695, Loss: 0.04122410656227508\n",
      "Epoch 696, Loss: 0.041203700678912165\n",
      "Epoch 697, Loss: 0.04118328554895126\n",
      "Epoch 698, Loss: 0.04116286085574551\n",
      "Epoch 699, Loss: 0.04114242628388957\n",
      "Epoch 700, Loss: 0.04112198151921215\n",
      "Epoch 701, Loss: 0.04110152624876926\n",
      "Epoch 702, Loss: 0.04108106016083706\n",
      "Epoch 703, Loss: 0.041060582944905145\n",
      "Epoch 704, Loss: 0.04104009429167\n",
      "Epoch 705, Loss: 0.04101959389302847\n",
      "Epoch 706, Loss: 0.040999081442071435\n",
      "Epoch 707, Loss: 0.04097855663307772\n",
      "Epoch 708, Loss: 0.040958019161507896\n",
      "Epoch 709, Loss: 0.04093746872399864\n",
      "Epoch 710, Loss: 0.04091690501835684\n",
      "Epoch 711, Loss: 0.040896327743554\n",
      "Epoch 712, Loss: 0.04087573659972095\n",
      "Epoch 713, Loss: 0.040855131288142395\n",
      "Epoch 714, Loss: 0.040834511511251954\n",
      "Epoch 715, Loss: 0.040813876972627026\n",
      "Epoch 716, Loss: 0.04079322737698399\n",
      "Epoch 717, Loss: 0.04077256243017351\n",
      "Epoch 718, Loss: 0.0407518818391761\n",
      "Epoch 719, Loss: 0.04073118531209751\n",
      "Epoch 720, Loss: 0.0407104725581647\n",
      "Epoch 721, Loss: 0.04068974328772155\n",
      "Epoch 722, Loss: 0.04066899721222505\n",
      "Epoch 723, Loss: 0.04064823404424142\n",
      "Epoch 724, Loss: 0.04062745349744251\n",
      "Epoch 725, Loss: 0.04060665528660214\n",
      "Epoch 726, Loss: 0.04058583912759297\n",
      "Epoch 727, Loss: 0.040565004737383115\n",
      "Epoch 728, Loss: 0.04054415183403312\n",
      "Epoch 729, Loss: 0.04052328013669305\n",
      "Epoch 730, Loss: 0.040502389365599765\n",
      "Epoch 731, Loss: 0.040481479242074174\n",
      "Epoch 732, Loss: 0.04046054948851896\n",
      "Epoch 733, Loss: 0.04043959982841597\n",
      "Epoch 734, Loss: 0.04041862998632438\n",
      "Epoch 735, Loss: 0.040397639687878344\n",
      "Epoch 736, Loss: 0.040376628659785335\n",
      "Epoch 737, Loss: 0.040355596629824325\n",
      "Epoch 738, Loss: 0.04033454332684419\n",
      "Epoch 739, Loss: 0.0403134684807623\n",
      "Epoch 740, Loss: 0.04029237182256323\n",
      "Epoch 741, Loss: 0.040271253084297604\n",
      "Epoch 742, Loss: 0.04025011199908107\n",
      "Epoch 743, Loss: 0.040228948301093616\n",
      "Epoch 744, Loss: 0.04020776172557862\n",
      "Epoch 745, Loss: 0.04018655200884256\n",
      "Epoch 746, Loss: 0.0401653188882544\n",
      "Epoch 747, Loss: 0.040144062102245574\n",
      "Epoch 748, Loss: 0.04012278139030959\n",
      "Epoch 749, Loss: 0.04010147649300238\n",
      "Epoch 750, Loss: 0.04008014715194232\n",
      "Epoch 751, Loss: 0.040058793109810586\n",
      "Epoch 752, Loss: 0.04003741411035174\n",
      "Epoch 753, Loss: 0.040016009898374304\n",
      "Epoch 754, Loss: 0.03999458021975149\n",
      "Epoch 755, Loss: 0.0399731248214224\n",
      "Epoch 756, Loss: 0.03995164345139281\n",
      "Epoch 757, Loss: 0.03993013585873653\n",
      "Epoch 758, Loss: 0.03990860179359692\n",
      "Epoch 759, Loss: 0.03988704100718822\n",
      "Epoch 760, Loss: 0.03986545325179741\n",
      "Epoch 761, Loss: 0.03984383828078601\n",
      "Epoch 762, Loss: 0.03982219584859195\n",
      "Epoch 763, Loss: 0.03980052571073188\n",
      "Epoch 764, Loss: 0.03977882762380333\n",
      "Epoch 765, Loss: 0.039757101345487274\n",
      "Epoch 766, Loss: 0.03973534663455063\n",
      "Epoch 767, Loss: 0.03971356325084895\n",
      "Epoch 768, Loss: 0.03969175095532947\n",
      "Epoch 769, Loss: 0.039669909510034025\n",
      "Epoch 770, Loss: 0.03964803867810222\n",
      "Epoch 771, Loss: 0.039626138223774886\n",
      "Epoch 772, Loss: 0.03960420791239748\n",
      "Epoch 773, Loss: 0.0395822475104238\n",
      "Epoch 774, Loss: 0.0395602567854196\n",
      "Epoch 775, Loss: 0.039538235506066735\n",
      "Epoch 776, Loss: 0.039516183442167195\n",
      "Epoch 777, Loss: 0.039494100364647254\n",
      "Epoch 778, Loss: 0.03947198604556197\n",
      "Epoch 779, Loss: 0.03944984025809967\n",
      "Epoch 780, Loss: 0.039427662776586624\n",
      "Epoch 781, Loss: 0.03940545337649196\n",
      "Epoch 782, Loss: 0.039383211834432615\n",
      "Epoch 783, Loss: 0.03936093792817845\n",
      "Epoch 784, Loss: 0.03933863143665756\n",
      "Epoch 785, Loss: 0.03931629213996176\n",
      "Epoch 786, Loss: 0.039293919819352104\n",
      "Epoch 787, Loss: 0.0392715142572647\n",
      "Epoch 788, Loss: 0.03924907523731656\n",
      "Epoch 789, Loss: 0.03922660254431164\n",
      "Epoch 790, Loss: 0.03920409596424704\n",
      "Epoch 791, Loss: 0.03918155528431944\n",
      "Epoch 792, Loss: 0.039158980292931383\n",
      "Epoch 793, Loss: 0.039136370779698094\n",
      "Epoch 794, Loss: 0.03911372653545427\n",
      "Epoch 795, Loss: 0.039091047352260926\n",
      "Epoch 796, Loss: 0.03906833302341253\n",
      "Epoch 797, Loss: 0.0390455833434443\n",
      "Epoch 798, Loss: 0.039022798108139516\n",
      "Epoch 799, Loss: 0.03899997711453703\n",
      "Epoch 800, Loss: 0.038977120160939155\n",
      "Epoch 801, Loss: 0.03895422704691925\n",
      "Epoch 802, Loss: 0.03893129757332988\n",
      "Epoch 803, Loss: 0.03890833154231081\n",
      "Epoch 804, Loss: 0.038885328757297506\n",
      "Epoch 805, Loss: 0.038862289023029295\n",
      "Epoch 806, Loss: 0.03883921214555814\n",
      "Epoch 807, Loss: 0.0388160979322573\n",
      "Epoch 808, Loss: 0.03879294619183024\n",
      "Epoch 809, Loss: 0.03876975673431957\n",
      "Epoch 810, Loss: 0.03874652937111629\n",
      "Epoch 811, Loss: 0.038723263914969136\n",
      "Epoch 812, Loss: 0.03869996017999384\n",
      "Epoch 813, Loss: 0.038676617981683065\n",
      "Epoch 814, Loss: 0.038653237136915854\n",
      "Epoch 815, Loss: 0.03862981746396769\n",
      "Epoch 816, Loss: 0.0386063587825205\n",
      "Epoch 817, Loss: 0.03858286091367288\n",
      "Epoch 818, Loss: 0.038559323679950276\n",
      "Epoch 819, Loss: 0.038535746905315686\n",
      "Epoch 820, Loss: 0.03851213041518013\n",
      "Epoch 821, Loss: 0.03848847403641346\n",
      "Epoch 822, Loss: 0.038464777597355226\n",
      "Epoch 823, Loss: 0.03844104092782572\n",
      "Epoch 824, Loss: 0.03841726385913728\n",
      "Epoch 825, Loss: 0.0383934462241054\n",
      "Epoch 826, Loss: 0.03836958785706047\n",
      "Epoch 827, Loss: 0.03834568859385914\n",
      "Epoch 828, Loss: 0.038321748271896154\n",
      "Epoch 829, Loss: 0.038297766730116305\n",
      "Epoch 830, Loss: 0.038273743809026414\n",
      "Epoch 831, Loss: 0.038249679350707395\n",
      "Epoch 832, Loss: 0.038225573198826704\n",
      "Epoch 833, Loss: 0.03820142519865068\n",
      "Epoch 834, Loss: 0.03817723519705713\n",
      "Epoch 835, Loss: 0.03815300304254799\n",
      "Epoch 836, Loss: 0.038128728585262346\n",
      "Epoch 837, Loss: 0.038104411676989094\n",
      "Epoch 838, Loss: 0.038080052171180274\n",
      "Epoch 839, Loss: 0.03805564992296427\n",
      "Epoch 840, Loss: 0.03803120478915912\n",
      "Epoch 841, Loss: 0.038006716628286\n",
      "Epoch 842, Loss: 0.037982185300582845\n",
      "Epoch 843, Loss: 0.03795761066801816\n",
      "Epoch 844, Loss: 0.037932992594304854\n",
      "Epoch 845, Loss: 0.03790833094491416\n",
      "Epoch 846, Loss: 0.03788362558708992\n",
      "Epoch 847, Loss: 0.03785887638986268\n",
      "Epoch 848, Loss: 0.03783408322406417\n",
      "Epoch 849, Loss: 0.03780924596234162\n",
      "Epoch 850, Loss: 0.03778436447917263\n",
      "Epoch 851, Loss: 0.037759438650879655\n",
      "Epoch 852, Loss: 0.03773446835564497\n",
      "Epoch 853, Loss: 0.03770945347352563\n",
      "Epoch 854, Loss: 0.03768439388646854\n",
      "Epoch 855, Loss: 0.0376592894783255\n",
      "Epoch 856, Loss: 0.037634140134868786\n",
      "Epoch 857, Loss: 0.03760894574380626\n",
      "Epoch 858, Loss: 0.03758370619479714\n",
      "Epoch 859, Loss: 0.03755842137946745\n",
      "Epoch 860, Loss: 0.037533091191425866\n",
      "Epoch 861, Loss: 0.037507715526279455\n",
      "Epoch 862, Loss: 0.03748229428164972\n",
      "Epoch 863, Loss: 0.03745682735718856\n",
      "Epoch 864, Loss: 0.03743131465459446\n",
      "Epoch 865, Loss: 0.03740575607762872\n",
      "Epoch 866, Loss: 0.037380151532131776\n",
      "Epoch 867, Loss: 0.03735450092603961\n",
      "Epoch 868, Loss: 0.037328804169400355\n",
      "Epoch 869, Loss: 0.037303061174390875\n",
      "Epoch 870, Loss: 0.03727727185533334\n",
      "Epoch 871, Loss: 0.037251436128712276\n",
      "Epoch 872, Loss: 0.03722555391319116\n",
      "Epoch 873, Loss: 0.03719962512962964\n",
      "Epoch 874, Loss: 0.03717364970110032\n",
      "Epoch 875, Loss: 0.037147627552906064\n",
      "Epoch 876, Loss: 0.03712155861259716\n",
      "Epoch 877, Loss: 0.03709544280998855\n",
      "Epoch 878, Loss: 0.03706928007717711\n",
      "Epoch 879, Loss: 0.0370430703485592\n",
      "Epoch 880, Loss: 0.037016813560848086\n",
      "Epoch 881, Loss: 0.036990509653091454\n",
      "Epoch 882, Loss: 0.036964158566689026\n",
      "Epoch 883, Loss: 0.03693776024541029\n",
      "Epoch 884, Loss: 0.03691131463541213\n",
      "Epoch 885, Loss: 0.0368848216852567\n",
      "Epoch 886, Loss: 0.036858281345929174\n",
      "Epoch 887, Loss: 0.03683169357085574\n",
      "Epoch 888, Loss: 0.036805058315921395\n",
      "Epoch 889, Loss: 0.036778375539488005\n",
      "Epoch 890, Loss: 0.03675164520241237\n",
      "Epoch 891, Loss: 0.03672486726806417\n",
      "Epoch 892, Loss: 0.036698041702344156\n",
      "Epoch 893, Loss: 0.036671168473702206\n",
      "Epoch 894, Loss: 0.036644247553155505\n",
      "Epoch 895, Loss: 0.03661727891430682\n",
      "Epoch 896, Loss: 0.036590262533362575\n",
      "Epoch 897, Loss: 0.03656319838915113\n",
      "Epoch 898, Loss: 0.03653608646314108\n",
      "Epoch 899, Loss: 0.03650892673945947\n",
      "Epoch 900, Loss: 0.036481719204910064\n",
      "Epoch 901, Loss: 0.03645446384899173\n",
      "Epoch 902, Loss: 0.036427160663916554\n",
      "Epoch 903, Loss: 0.0363998096446283\n",
      "Epoch 904, Loss: 0.036372410788820586\n",
      "Epoch 905, Loss: 0.03634496409695529\n",
      "Epoch 906, Loss: 0.03631746957228064\n",
      "Epoch 907, Loss: 0.03628992722084969\n",
      "Epoch 908, Loss: 0.03626233705153838\n",
      "Epoch 909, Loss: 0.03623469907606394\n",
      "Epoch 910, Loss: 0.036207013309002896\n",
      "Epoch 911, Loss: 0.036179279767809436\n",
      "Epoch 912, Loss: 0.036151498472833436\n",
      "Epoch 913, Loss: 0.036123669447338635\n",
      "Epoch 914, Loss: 0.03609579271752059\n",
      "Epoch 915, Loss: 0.03606786831252492\n",
      "Epoch 916, Loss: 0.03603989626446504\n",
      "Epoch 917, Loss: 0.03601187660844025\n",
      "Epoch 918, Loss: 0.0359838093825536\n",
      "Epoch 919, Loss: 0.03595569462792963\n",
      "Epoch 920, Loss: 0.03592753238873211\n",
      "Epoch 921, Loss: 0.03589932271218189\n",
      "Epoch 922, Loss: 0.035871065648574285\n",
      "Epoch 923, Loss: 0.03584276125129681\n",
      "Epoch 924, Loss: 0.035814409576846416\n",
      "Epoch 925, Loss: 0.035786010684847054\n",
      "Epoch 926, Loss: 0.035757564638066903\n",
      "Epoch 927, Loss: 0.03572907150243542\n",
      "Epoch 928, Loss: 0.03570053134706058\n",
      "Epoch 929, Loss: 0.035671944244245836\n",
      "Epoch 930, Loss: 0.035643310269506824\n",
      "Epoch 931, Loss: 0.035614629501588335\n",
      "Epoch 932, Loss: 0.03558590202248083\n",
      "Epoch 933, Loss: 0.035557127917437016\n",
      "Epoch 934, Loss: 0.03552830727498807\n",
      "Epoch 935, Loss: 0.03549944018696015\n",
      "Epoch 936, Loss: 0.035470526748490265\n",
      "Epoch 937, Loss: 0.03544156705804247\n",
      "Epoch 938, Loss: 0.0354125612174234\n",
      "Epoch 939, Loss: 0.0353835093317983\n",
      "Epoch 940, Loss: 0.0353544115097062\n",
      "Epoch 941, Loss: 0.03532526786307547\n",
      "Epoch 942, Loss: 0.035296078507238995\n",
      "Epoch 943, Loss: 0.03526684356094895\n",
      "Epoch 944, Loss: 0.03523756314639203\n",
      "Epoch 945, Loss: 0.03520823738920365\n",
      "Epoch 946, Loss: 0.03517886641848276\n",
      "Epoch 947, Loss: 0.03514945036680587\n",
      "Epoch 948, Loss: 0.035119989370241245\n",
      "Epoch 949, Loss: 0.03509048356836266\n",
      "Epoch 950, Loss: 0.03506093310426311\n",
      "Epoch 951, Loss: 0.03503133812456815\n",
      "Epoch 952, Loss: 0.03500169877944922\n",
      "Epoch 953, Loss: 0.034972015222636495\n",
      "Epoch 954, Loss: 0.034942287611431734\n",
      "Epoch 955, Loss: 0.03491251610672065\n",
      "Epoch 956, Loss: 0.034882700872985284\n",
      "Epoch 957, Loss: 0.03485284207831597\n",
      "Epoch 958, Loss: 0.03482293989442305\n",
      "Epoch 959, Loss: 0.03479299449664843\n",
      "Epoch 960, Loss: 0.034763006063976774\n",
      "Epoch 961, Loss: 0.03473297477904636\n",
      "Epoch 962, Loss: 0.03470290082815999\n",
      "Epoch 963, Loss: 0.03467278440129506\n",
      "Epoch 964, Loss: 0.0346426256921139\n",
      "Epoch 965, Loss: 0.034612424897973476\n",
      "Epoch 966, Loss: 0.03458218221993497\n",
      "Epoch 967, Loss: 0.03455189786277282\n",
      "Epoch 968, Loss: 0.03452157203498369\n",
      "Epoch 969, Loss: 0.03449120494879513\n",
      "Epoch 970, Loss: 0.034460796820173605\n",
      "Epoch 971, Loss: 0.03443034786883261\n",
      "Epoch 972, Loss: 0.034399858318239995\n",
      "Epoch 973, Loss: 0.03436932839562554\n",
      "Epoch 974, Loss: 0.03433875833198747\n",
      "Epoch 975, Loss: 0.03430814836209926\n",
      "Epoch 976, Loss: 0.0342774987245156\n",
      "Epoch 977, Loss: 0.03424680966157845\n",
      "Epoch 978, Loss: 0.034216081419422235\n",
      "Epoch 979, Loss: 0.034185314247978986\n",
      "Epoch 980, Loss: 0.034154508400983066\n",
      "Epoch 981, Loss: 0.03412366413597551\n",
      "Epoch 982, Loss: 0.03409278171430775\n",
      "Epoch 983, Loss: 0.03406186140114529\n",
      "Epoch 984, Loss: 0.0340309034654707\n",
      "Epoch 985, Loss: 0.03399990818008633\n",
      "Epoch 986, Loss: 0.03396887582161672\n",
      "Epoch 987, Loss: 0.03393780667051022\n",
      "Epoch 988, Loss: 0.03390670101104063\n",
      "Epoch 989, Loss: 0.03387555913130807\n",
      "Epoch 990, Loss: 0.03384438132323966\n",
      "Epoch 991, Loss: 0.03381316788258951\n",
      "Epoch 992, Loss: 0.033781919108938546\n",
      "Epoch 993, Loss: 0.03375063530569363\n",
      "Epoch 994, Loss: 0.0337193167800864\n",
      "Epoch 995, Loss: 0.033687963843171555\n",
      "Epoch 996, Loss: 0.03365657680982466\n",
      "Epoch 997, Loss: 0.03362515599873961\n",
      "Epoch 998, Loss: 0.033593701732425464\n",
      "Epoch 999, Loss: 0.03356221433720286\n",
      "Train accuracy:  1.0\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 1]\n",
      " [1 0 0]]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from test_nn import *\n",
    "\n",
    "nn = NeuralNetwork([3, 6, 6, 3], [Sigmoid(), Sigmoid(), Sigmoid()], MeanSquaredError())\n",
    "\n",
    "# x_train = np.array([[0, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 0], [1, 1, 1], [0, 1, 1], [1, 0, 0]])\n",
    "# y_train = np.array([[1], [1], [0], [1], [0], [0], [1]])\n",
    "x_train = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [1, 1, 0], [1, 0, 1], [1, 1, 1], [0, 0, 0]])\n",
    "y_train = np.array([[1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0]])\n",
    "nn.train(x_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "yhat = np.array([nn.predict_binary(x) for x in x_train])\n",
    "print(\"Train accuracy: \", accuracy_binary(yhat, y_train))\n",
    "print(yhat)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (8,3) and (784,512) not aligned: 3 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnn_single\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m nn \u001b[38;5;241m=\u001b[39m NN(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m784\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.01\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m yhat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([nn\u001b[38;5;241m.\u001b[39mpredict(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m x_test])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy(yhat, y_test))\n",
      "File \u001b[0;32m~/Documents/GitHub/tyler-cnn/nn_single.py:50\u001b[0m, in \u001b[0;36mNN.train\u001b[0;34m(self, input_data, target, epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data, target, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 50\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(input_data, target)\n",
      "File \u001b[0;32m~/Documents/GitHub/tyler-cnn/nn_single.py:16\u001b[0m, in \u001b[0;36mNN.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Input to hidden layer\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_input \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights_input_hidden\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_hidden\n\u001b[1;32m     17\u001b[0m     sig \u001b[38;5;241m=\u001b[39m Sigmoid()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_output \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_input)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (8,3) and (784,512) not aligned: 3 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "from nn_single import *\n",
    "\n",
    "nn = NN(input_size=784, hidden_size=512, output_size=10, learning_rate=.01)\n",
    "nn.train(x_train[:500], y_train[:500], epochs=20)\n",
    "\n",
    "yhat = np.array([nn.predict(x) for x in x_test])\n",
    "\n",
    "print(\"Accuracy: \", accuracy(yhat, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
